{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"colab":{"provenance":[],"gpuType":"T4"},"accelerator":"GPU","kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":31240,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Imports","metadata":{"id":"Nt0MigvwYQ3c"}},{"cell_type":"code","source":"!pip install --upgrade git+https://github.com/evfro/polara.git@develop#egg=polara","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5D6M92ewclDa","outputId":"8814ba01-4467-41e9-a405-e35d231b1849","trusted":true,"execution":{"iopub.status.busy":"2025-12-25T00:33:21.201932Z","iopub.execute_input":"2025-12-25T00:33:21.202160Z","iopub.status.idle":"2025-12-25T00:33:29.336177Z","shell.execute_reply.started":"2025-12-25T00:33:21.202133Z","shell.execute_reply":"2025-12-25T00:33:29.335261Z"}},"outputs":[{"name":"stdout","text":"Collecting polara\n  Cloning https://github.com/evfro/polara.git (to revision develop) to /tmp/pip-install-ctg0fay8/polara_244863647da44536a9f4dda9fa98c121\n  Running command git clone --filter=blob:none --quiet https://github.com/evfro/polara.git /tmp/pip-install-ctg0fay8/polara_244863647da44536a9f4dda9fa98c121\n  Running command git checkout -b develop --track origin/develop\n  Switched to a new branch 'develop'\n  Branch 'develop' set up to track remote branch 'develop' from 'origin'.\n  Resolved https://github.com/evfro/polara.git to commit 8fdb520722f4c80c20709dbbda5b0896c4ca6f7a\n  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\nBuilding wheels for collected packages: polara\n  Building wheel for polara (setup.py) ... \u001b[?25l\u001b[?25hdone\n  Created wheel for polara: filename=polara-0.7.2.dev0-py3-none-any.whl size=90560 sha256=18ef96234c5aea928427700cb0191983d3db2088d6eb11bdedf388412b0b5172\n  Stored in directory: /tmp/pip-ephem-wheel-cache-xd1vs_ka/wheels/0d/0d/28/cc13e491ae8db91f2ad2815ecf9ce7dad0d2721a53a839628c\nSuccessfully built polara\nInstalling collected packages: polara\nSuccessfully installed polara-0.7.2.dev0\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nfrom scipy.sparse import csr_matrix\nimport seaborn as sns\n\nimport torch\nimport torch.nn as nn\nfrom polara import get_movielens_data\n\nfrom tqdm import tqdm","metadata":{"id":"pE6xt3rNYTgW","trusted":true,"execution":{"iopub.status.busy":"2025-12-25T00:33:29.337120Z","iopub.execute_input":"2025-12-25T00:33:29.337380Z","iopub.status.idle":"2025-12-25T00:33:35.624420Z","shell.execute_reply.started":"2025-12-25T00:33:29.337349Z","shell.execute_reply":"2025-12-25T00:33:35.623772Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nprint(f\"Using device: {device}\")","metadata":{"id":"21cE7J7kn48a","colab":{"base_uri":"https://localhost:8080/"},"outputId":"4f5d944d-ad16-4b2d-bc48-542820985980","trusted":true,"execution":{"iopub.status.busy":"2025-12-25T00:33:35.626091Z","iopub.execute_input":"2025-12-25T00:33:35.626748Z","iopub.status.idle":"2025-12-25T00:33:35.713877Z","shell.execute_reply.started":"2025-12-25T00:33:35.626725Z","shell.execute_reply":"2025-12-25T00:33:35.713172Z"}},"outputs":[{"name":"stdout","text":"Using device: cuda\n","output_type":"stream"}],"execution_count":3},{"cell_type":"markdown","source":"# Asymmetric GNN","metadata":{"id":"VMNXYR5KYUdO"}},{"cell_type":"markdown","source":"## Hyperboloid Operations","metadata":{"id":"mC8OTf-VbNs0"}},{"cell_type":"code","source":"def minkowski_inner(x, y):\n    return -x[..., 0] * y[..., 0] + (x[..., 1:] * y[..., 1:]).sum(dim=-1)\n\ndef project_to_hyperboloid(x):\n    x0 = torch.sqrt(1.0 + (x[..., 1:] ** 2).sum(dim=-1, keepdim=True))\n    return torch.cat([x0, x[..., 1:]], dim=-1)","metadata":{"id":"4wCuVZy_S2p4","trusted":true,"execution":{"iopub.status.busy":"2025-12-25T00:33:42.516208Z","iopub.execute_input":"2025-12-25T00:33:42.516477Z","iopub.status.idle":"2025-12-25T00:33:42.521457Z","shell.execute_reply.started":"2025-12-25T00:33:42.516456Z","shell.execute_reply":"2025-12-25T00:33:42.520644Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"def tangent_projection(x, v):\n    return v + minkowski_inner(x, v).unsqueeze(-1) * x\n\ndef exp_map(x, v):\n    v_norm = torch.sqrt(torch.clamp(minkowski_inner(v, v), min=1e-9)).unsqueeze(-1)\n    return torch.cosh(v_norm) * x + torch.sinh(v_norm) * v / v_norm\n\ndef log_map(x, y):\n    ip = -minkowski_inner(x, y)\n    ip = torch.clamp(ip, min=1.0 + 1e-7)\n\n    d = torch.arccosh(ip)\n\n    direction = y - ip.unsqueeze(-1) * x\n\n    sinh_d = torch.sinh(d).clamp(min=1e-7)\n    return d.unsqueeze(-1) * direction / sinh_d.unsqueeze(-1)\n","metadata":{"id":"thA2IJaMYbx6","trusted":true,"execution":{"iopub.status.busy":"2025-12-25T00:33:42.762378Z","iopub.execute_input":"2025-12-25T00:33:42.762866Z","iopub.status.idle":"2025-12-25T00:33:42.767679Z","shell.execute_reply.started":"2025-12-25T00:33:42.762844Z","shell.execute_reply":"2025-12-25T00:33:42.766990Z"}},"outputs":[],"execution_count":5},{"cell_type":"markdown","source":"## Einstein Midpoint","metadata":{"id":"Hu0J91WmbnyN"}},{"cell_type":"code","source":"def hyperboloid_to_klein(x):\n    return x[..., 1:] / x[..., :1]\n\ndef klein_to_hyperboloid(x):\n    norm_sq = (x ** 2).sum(dim=-1, keepdim=True)\n    norm_sq = torch.clamp(norm_sq, max=1.0 - 1e-7)\n    x0 = 1.0 / torch.sqrt(1.0 - norm_sq)\n    return torch.cat([x0, x0 * x], dim=-1)","metadata":{"id":"RPjCRMNeYeUo","trusted":true,"execution":{"iopub.status.busy":"2025-12-25T00:33:43.682158Z","iopub.execute_input":"2025-12-25T00:33:43.682432Z","iopub.status.idle":"2025-12-25T00:33:43.687368Z","shell.execute_reply.started":"2025-12-25T00:33:43.682412Z","shell.execute_reply":"2025-12-25T00:33:43.686583Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"def einstein_midpoint(x):\n    x_k = hyperboloid_to_klein(x)\n    norm_sq = (x_k ** 2).sum(dim=-1, keepdim=True)\n    gamma = 1.0 / (torch.clamp(1.0 - norm_sq, min=1e-7))\n    p = (gamma * x_k).sum(dim=0) / torch.clamp(gamma.sum(dim=0), min=1e-7)\n\n    return klein_to_hyperboloid(p)","metadata":{"id":"47xSEKCrYguE","trusted":true,"execution":{"iopub.status.busy":"2025-12-25T00:33:43.913243Z","iopub.execute_input":"2025-12-25T00:33:43.913764Z","iopub.status.idle":"2025-12-25T00:33:43.917745Z","shell.execute_reply.started":"2025-12-25T00:33:43.913742Z","shell.execute_reply":"2025-12-25T00:33:43.917055Z"}},"outputs":[],"execution_count":7},{"cell_type":"markdown","source":"## Item embeddings initialization","metadata":{"id":"vTCuButGbso8"}},{"cell_type":"code","source":"def init_hyperboloid(n, dim, scale=1e-3):\n    x = torch.randn(n, dim, device=device) * scale\n    x = torch.cat([torch.zeros(n, 1, device=device), x], dim=1)\n    return project_to_hyperboloid(x)","metadata":{"id":"Q5WEDLIpYiuc","trusted":true,"execution":{"iopub.status.busy":"2025-12-25T01:59:48.513710Z","iopub.execute_input":"2025-12-25T01:59:48.514423Z","iopub.status.idle":"2025-12-25T01:59:48.518258Z","shell.execute_reply.started":"2025-12-25T01:59:48.514396Z","shell.execute_reply":"2025-12-25T01:59:48.517533Z"}},"outputs":[],"execution_count":42},{"cell_type":"markdown","source":"## Hyperbolic GNN","metadata":{"id":"H1UTjTBScTAp"}},{"cell_type":"code","source":"class HyperbolicItemGNNLayer(nn.Module):\n    def __init__(self, alpha=0.5):\n        super().__init__()\n        self.alpha = alpha\n\n    def forward(self, item_emb, item_neighbors):\n        new_emb = []\n\n        for i, neigh in enumerate(item_neighbors):\n            if len(neigh) == 0:\n                new_emb.append(item_emb[i])\n                continue\n\n            agg = einstein_midpoint(item_emb[neigh])\n            v = item_emb[i]\n            delta = log_map(v, agg)\n            updated = exp_map(v, self.alpha * delta)\n\n            new_emb.append(project_to_hyperboloid(updated))\n        return torch.stack(new_emb)","metadata":{"id":"QPDs0C3ClYx7","trusted":true,"execution":{"iopub.status.busy":"2025-12-25T00:33:47.226320Z","iopub.execute_input":"2025-12-25T00:33:47.226620Z","iopub.status.idle":"2025-12-25T00:33:47.232036Z","shell.execute_reply.started":"2025-12-25T00:33:47.226598Z","shell.execute_reply":"2025-12-25T00:33:47.231234Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"class HyperbolicItemGNN(nn.Module):\n    def __init__(self, n_items, dim, n_layers):\n        super().__init__()\n        self.item_emb = nn.Parameter(init_hyperboloid(n_items, dim))\n        self.layers = nn.ModuleList(\n            [HyperbolicItemGNNLayer() for _ in range(n_layers)]\n        )\n\n    def forward(self, item_neighbors):\n        x = self.item_emb\n        for layer in self.layers:\n            x = layer(x, item_neighbors)\n        return x","metadata":{"id":"h4p8S-ReYqtg","trusted":true,"execution":{"iopub.status.busy":"2025-12-25T00:33:47.317126Z","iopub.execute_input":"2025-12-25T00:33:47.317318Z","iopub.status.idle":"2025-12-25T00:33:47.321576Z","shell.execute_reply.started":"2025-12-25T00:33:47.317304Z","shell.execute_reply":"2025-12-25T00:33:47.320948Z"}},"outputs":[],"execution_count":10},{"cell_type":"markdown","source":"## User embeddings","metadata":{"id":"YXKXk9InoRea"}},{"cell_type":"code","source":"def compute_user_embedding(user_history, item_emb):\n    return einstein_midpoint(item_emb[user_history])","metadata":{"id":"hqD9A3F4oUg_","trusted":true,"execution":{"iopub.status.busy":"2025-12-25T00:33:50.406986Z","iopub.execute_input":"2025-12-25T00:33:50.407607Z","iopub.status.idle":"2025-12-25T00:33:50.410951Z","shell.execute_reply.started":"2025-12-25T00:33:50.407583Z","shell.execute_reply":"2025-12-25T00:33:50.410216Z"}},"outputs":[],"execution_count":11},{"cell_type":"markdown","source":"## Loss-function","metadata":{"id":"e1OIfNzhh23u"}},{"cell_type":"code","source":"class WMRBLoss(nn.Module):\n    def __init__(self, margin=1.0):\n        super().__init__()\n        self.margin = margin\n\n    def forward(self, user_emb, pos_item, neg_items):\n        d_pos = minkowski_inner(user_emb, pos_item)\n        d_neg = minkowski_inner(\n            user_emb.unsqueeze(1),\n            neg_items\n        )\n\n        r = torch.relu(self.margin - d_pos.unsqueeze(1) + d_neg).sum(dim=1)\n        return torch.log1p(r).mean()","metadata":{"id":"JILmpS8GYssP","trusted":true,"execution":{"iopub.status.busy":"2025-12-25T00:33:50.663771Z","iopub.execute_input":"2025-12-25T00:33:50.664243Z","iopub.status.idle":"2025-12-25T00:33:50.668634Z","shell.execute_reply.started":"2025-12-25T00:33:50.664221Z","shell.execute_reply":"2025-12-25T00:33:50.667930Z"}},"outputs":[],"execution_count":12},{"cell_type":"markdown","source":"## Optimizer","metadata":{"id":"qYUh6Ojgh7vA"}},{"cell_type":"code","source":"class RSGD(torch.optim.Optimizer):\n    def __init__(self, params, lr=0.05):\n        super().__init__(params, dict(lr=lr))\n\n    @torch.no_grad()\n    def step(self):\n        for group in self.param_groups:\n            lr = group[\"lr\"]\n            for p in group[\"params\"]:\n                if p.grad is None:\n                    continue\n\n                g = p.grad\n                g[..., 0] *= -1  # inverse Minkowski metric\n\n                g = tangent_projection(p, g)\n                p_new = exp_map(p, -lr * g)\n                p.copy_(project_to_hyperboloid(p_new))","metadata":{"id":"hRThBVtWYu8m","trusted":true,"execution":{"iopub.status.busy":"2025-12-25T00:33:50.940021Z","iopub.execute_input":"2025-12-25T00:33:50.940532Z","iopub.status.idle":"2025-12-25T00:33:50.945769Z","shell.execute_reply.started":"2025-12-25T00:33:50.940492Z","shell.execute_reply":"2025-12-25T00:33:50.945054Z"}},"outputs":[],"execution_count":13},{"cell_type":"markdown","source":"## Recommender system","metadata":{"id":"T9hCoju9iHJE"}},{"cell_type":"code","source":"class HyperbolicItemGNNRecommender(nn.Module):\n    def __init__(self, n_items, dim, n_layers):\n        super().__init__()\n        self.gnn = HyperbolicItemGNN(n_items, dim, n_layers)\n        self.loss_fn = WMRBLoss()\n\n    def forward(self, user_histories, pos_items, neg_items, item_neighbors):\n        item_emb = self.gnn(item_neighbors)\n\n        user_embs = []\n        for hist in user_histories:\n            if len(hist) == 0:\n                user_embs.append(torch.zeros_like(item_emb[0]))\n            else:\n                hist_tensor = torch.tensor(hist, dtype=torch.long, device=item_emb.device)\n                hist_emb = item_emb[hist_tensor]\n                user_emb = einstein_midpoint(hist_emb)\n                user_embs.append(user_emb)\n\n        user_embs = torch.stack(user_embs)\n\n        pos = item_emb[pos_items]\n        neg = item_emb[neg_items]\n\n        return self.loss_fn(user_embs, pos, neg)","metadata":{"id":"2uQNKu9LYxE4","trusted":true,"execution":{"iopub.status.busy":"2025-12-25T00:33:53.617250Z","iopub.execute_input":"2025-12-25T00:33:53.617542Z","iopub.status.idle":"2025-12-25T00:33:53.623207Z","shell.execute_reply.started":"2025-12-25T00:33:53.617520Z","shell.execute_reply":"2025-12-25T00:33:53.622547Z"}},"outputs":[],"execution_count":14},{"cell_type":"markdown","source":"# Data Preprocessing","metadata":{"id":"nVBV-Fh1bbMJ"}},{"cell_type":"markdown","source":"Будем обучаться на `MovieLens 1M`","metadata":{"id":"v4_JLRrvbtwr"}},{"cell_type":"code","source":"data = get_movielens_data(include_time=True)","metadata":{"id":"xq27RaS7btOV","trusted":true,"execution":{"iopub.status.busy":"2025-12-25T00:33:56.863024Z","iopub.execute_input":"2025-12-25T00:33:56.863769Z","iopub.status.idle":"2025-12-25T00:33:57.830381Z","shell.execute_reply.started":"2025-12-25T00:33:56.863745Z","shell.execute_reply":"2025-12-25T00:33:57.829785Z"}},"outputs":[],"execution_count":15},{"cell_type":"code","source":"data = data.sort_values(\"timestamp\").reset_index(drop=True)","metadata":{"id":"techUzccc4YE","trusted":true,"execution":{"iopub.status.busy":"2025-12-25T00:33:57.831332Z","iopub.execute_input":"2025-12-25T00:33:57.831577Z","iopub.status.idle":"2025-12-25T00:33:57.939957Z","shell.execute_reply.started":"2025-12-25T00:33:57.831561Z","shell.execute_reply":"2025-12-25T00:33:57.939386Z"}},"outputs":[],"execution_count":16},{"cell_type":"code","source":"split_date = data[\"timestamp\"].quantile(0.95)\n\ndata_split = dict()\n\n#train data\ndata_split[\"train\"] = data[data[\"timestamp\"] <= split_date]\n\n#test\ndata_split[\"test\"] = (\n    data[data[\"timestamp\"] > split_date]\n    .groupby(\"userid\")\n    .apply(lambda x: x.iloc[:-1])\n    .reset_index(drop=True)\n)\n\n#holdout\ndata_split[\"holdout\"] = (\n    data[data[\"timestamp\"] > split_date]\n    .groupby(\"userid\")\n    .apply(lambda x: x.iloc[-1])\n    .reset_index(drop=True)\n)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LQ21VOJBc8CM","outputId":"74e98037-af36-4e66-f98c-8652192317fa","trusted":true,"execution":{"iopub.status.busy":"2025-12-25T00:33:58.119957Z","iopub.execute_input":"2025-12-25T00:33:58.120224Z","iopub.status.idle":"2025-12-25T00:33:58.248582Z","shell.execute_reply.started":"2025-12-25T00:33:58.120205Z","shell.execute_reply":"2025-12-25T00:33:58.247806Z"}},"outputs":[{"name":"stderr","text":"/tmp/ipykernel_47/2209898973.py:12: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n  .apply(lambda x: x.iloc[:-1])\n/tmp/ipykernel_47/2209898973.py:20: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n  .apply(lambda x: x.iloc[-1])\n","output_type":"stream"}],"execution_count":17},{"cell_type":"code","source":"data_types = [\"train\", \"test\", \"holdout\"]\n\nrating_matrix = dict()\nuser_cnt = len(data[\"userid\"].unique())\nitem_cnt = len(data[\"movieid\"].unique())\n\nuser_cats = data[\"userid\"].astype(\"category\")\nitem_cats = data[\"movieid\"].astype(\"category\")\n\nuser_match_dict = {user_cat: ind for ind, user_cat in enumerate(user_cats.cat.categories.tolist())}\nitem_match_dict = {item_cat: ind for ind, item_cat in enumerate(item_cats.cat.categories.tolist())}\n\nfor sample_type in data_types:\n    user_indices = [user_match_dict[user] for user in data_split[sample_type][\"userid\"].values]\n    item_indices = [item_match_dict[item] for item in data_split[sample_type][\"movieid\"].values]\n\n    rating_matrix[sample_type] = csr_matrix(\n        (\n            data_split[sample_type][\"rating\"].values,\n            (\n                user_indices,\n                item_indices\n            )\n        ),\n        shape=(user_cnt, item_cnt),\n        dtype=\"f8\"\n    )","metadata":{"id":"btMz51yCc900","trusted":true,"execution":{"iopub.status.busy":"2025-12-25T00:34:03.767045Z","iopub.execute_input":"2025-12-25T00:34:03.767311Z","iopub.status.idle":"2025-12-25T00:34:04.346204Z","shell.execute_reply.started":"2025-12-25T00:34:03.767293Z","shell.execute_reply":"2025-12-25T00:34:04.345615Z"}},"outputs":[],"execution_count":18},{"cell_type":"code","source":"rating_matrix[\"train\"] = (rating_matrix[\"train\"] > 0).astype(float)\nrating_matrix[\"test\"] = (rating_matrix[\"test\"] > 0).astype(float)\nrating_matrix[\"holdout\"] = (rating_matrix[\"holdout\"] > 0).astype(float)","metadata":{"id":"J0Kq97-5FVYP","trusted":true,"execution":{"iopub.status.busy":"2025-12-25T00:34:04.347307Z","iopub.execute_input":"2025-12-25T00:34:04.347587Z","iopub.status.idle":"2025-12-25T00:34:04.357784Z","shell.execute_reply.started":"2025-12-25T00:34:04.347567Z","shell.execute_reply":"2025-12-25T00:34:04.357145Z"}},"outputs":[],"execution_count":19},{"cell_type":"code","source":"item_neighbors_sparse = (rating_matrix[\"train\"].T @ rating_matrix[\"train\"] > 100)\n\nitem_neighbors = []\n\nfor i in range(item_neighbors_sparse.shape[0]):\n    row = item_neighbors_sparse.getrow(i)\n    item_neighbors.append(row.indices)","metadata":{"id":"4-Vb44rkfY20","trusted":true,"execution":{"iopub.status.busy":"2025-12-25T02:33:34.145713Z","iopub.execute_input":"2025-12-25T02:33:34.146400Z","iopub.status.idle":"2025-12-25T02:33:40.507343Z","shell.execute_reply.started":"2025-12-25T02:33:34.146374Z","shell.execute_reply":"2025-12-25T02:33:40.506762Z"}},"outputs":[],"execution_count":49},{"cell_type":"code","source":"users_items = []\nfor i in range(rating_matrix[\"train\"].shape[0]):\n    row = rating_matrix[\"train\"].getrow(i)\n    users_items.append(row.indices)","metadata":{"id":"Je174eIw5gyK","trusted":true,"execution":{"iopub.status.busy":"2025-12-25T00:35:16.108802Z","iopub.execute_input":"2025-12-25T00:35:16.109073Z","iopub.status.idle":"2025-12-25T00:35:16.328255Z","shell.execute_reply.started":"2025-12-25T00:35:16.109054Z","shell.execute_reply":"2025-12-25T00:35:16.327691Z"}},"outputs":[],"execution_count":21},{"cell_type":"markdown","source":"# Training","metadata":{"id":"3iWPe3yA95j9"}},{"cell_type":"code","source":"class BatchGenerator:\n    \"\"\"Sequential batch generator для next-item prediction\"\"\"\n    def __init__(self, users_items, n_items, batch_size=256, n_neg=10, min_history=1):\n        self.users_items = users_items\n        self.n_items = n_items\n        self.batch_size = batch_size\n        self.n_neg = n_neg\n        self.min_history = min_history\n\n        self.valid_users = [i for i, items in enumerate(users_items)\n                           if len(items) > min_history]\n\n        print(f\"Valid users: {len(self.valid_users)} / {len(users_items)}\")\n\n    def __iter__(self):\n        np.random.shuffle(self.valid_users)\n\n        for i in range(0, len(self.valid_users), self.batch_size):\n            batch_users = self.valid_users[i:i+self.batch_size]\n\n            user_histories = []\n            pos_items = []\n            neg_items_list = []\n\n            for user_id in batch_users:\n                items = self.users_items[user_id]\n\n                split_idx = np.random.randint(self.min_history, len(items))\n                history = items[:split_idx].tolist()\n                target = items[split_idx]\n\n                neg_candidates = np.setdiff1d(np.arange(self.n_items), items)\n                if len(neg_candidates) >= self.n_neg:\n                    neg = np.random.choice(neg_candidates, size=self.n_neg, replace=False)\n                else:\n                    neg = np.random.choice(neg_candidates, size=self.n_neg, replace=True)\n\n                user_histories.append(history)\n                pos_items.append(target)\n                neg_items_list.append(neg.tolist())\n\n            yield (\n                user_histories,\n                torch.tensor(pos_items, dtype=torch.long, device=device),\n                torch.tensor(neg_items_list, dtype=torch.long, device=device)\n            )","metadata":{"id":"hi8rUTcSR7yp","trusted":true,"execution":{"iopub.status.busy":"2025-12-25T02:33:44.730712Z","iopub.execute_input":"2025-12-25T02:33:44.730997Z","iopub.status.idle":"2025-12-25T02:33:44.738814Z","shell.execute_reply.started":"2025-12-25T02:33:44.730976Z","shell.execute_reply":"2025-12-25T02:33:44.738108Z"}},"outputs":[],"execution_count":50},{"cell_type":"code","source":"model = HyperbolicItemGNNRecommender(\n    n_items=item_cnt,\n    dim=32,\n    n_layers=2\n)\n\nmodel = model.to(device)\n\noptimizer = RSGD(model.parameters(), lr=1e-2)\n\nbatch_gen = BatchGenerator(\n    users_items=users_items,\n    n_items=item_cnt,\n    batch_size=1024,\n    n_neg=10\n)\n\nfor epoch in range(10):\n    total_loss = 0\n    n_batches = 0\n\n    for user_histories, pos_items, neg_items in tqdm(batch_gen):\n        optimizer.zero_grad()\n        loss = model(user_histories, pos_items, neg_items, item_neighbors)\n\n        if torch.isnan(loss):\n            print(\"⚠️ NaN detected! Skipping...\")\n            continue\n\n        loss.backward()\n        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n        optimizer.step()\n\n        total_loss += loss.item()\n        n_batches += 1\n\n    print(f\"Epoch {epoch+1}: Loss = {total_loss / n_batches:.4f}\")","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CvmroCy19770","outputId":"9497f74c-a155-4d71-f981-36f9f58dabc0","trusted":true,"execution":{"iopub.status.busy":"2025-12-25T02:33:45.218443Z","iopub.execute_input":"2025-12-25T02:33:45.218738Z","iopub.status.idle":"2025-12-25T02:50:51.273627Z","shell.execute_reply.started":"2025-12-25T02:33:45.218717Z","shell.execute_reply":"2025-12-25T02:50:51.272942Z"}},"outputs":[{"name":"stdout","text":"Valid users: 6036 / 6040\n","output_type":"stream"},{"name":"stderr","text":"6it [01:43, 17.17s/it]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1: Loss = 2.3979\n","output_type":"stream"},{"name":"stderr","text":"6it [01:42, 17.04s/it]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 2: Loss = 2.3979\n","output_type":"stream"},{"name":"stderr","text":"6it [01:42, 17.07s/it]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 3: Loss = 2.3979\n","output_type":"stream"},{"name":"stderr","text":"6it [01:42, 17.11s/it]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 4: Loss = 2.3979\n","output_type":"stream"},{"name":"stderr","text":"6it [01:42, 17.11s/it]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 5: Loss = 2.3979\n","output_type":"stream"},{"name":"stderr","text":"6it [01:42, 17.10s/it]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 6: Loss = 2.3979\n","output_type":"stream"},{"name":"stderr","text":"6it [01:42, 17.14s/it]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 7: Loss = 2.3979\n","output_type":"stream"},{"name":"stderr","text":"6it [01:42, 17.07s/it]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 8: Loss = 2.3979\n","output_type":"stream"},{"name":"stderr","text":"6it [01:42, 17.10s/it]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 9: Loss = 2.3979\n","output_type":"stream"},{"name":"stderr","text":"6it [01:42, 17.11s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch 10: Loss = 2.3979\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}],"execution_count":51},{"cell_type":"markdown","source":"# Evaluation","metadata":{}},{"cell_type":"code","source":"rating_matrix[\"test\"] += rating_matrix[\"train\"]\n\nusers_items_test_history = []\nfor i in range(rating_matrix[\"test\"].shape[0]):\n    row = rating_matrix[\"test\"].getrow(i)\n    users_items_test_history.append(row.indices)\n\nusers_items_holdout_targets = []\nfor i in range(rating_matrix[\"holdout\"].shape[0]):\n    row = rating_matrix[\"holdout\"].getrow(i)\n    if row.nnz > 0:\n        users_items_holdout_targets.append(row.indices[0])\n    else:\n        users_items_holdout_targets.append(None)\n\nvalid_users_eval = []\nfor i in range(user_cnt):\n    if len(users_items_test_history[i]) > 0 and users_items_holdout_targets[i] is not None:\n        valid_users_eval.append(i)\n\nitem_embeddings = model.gnn(item_neighbors)\n\ndef get_recommendations(user_embedding, item_embeddings, user_history, k):\n    # Calculate similarity between user embedding and all item embeddings\n    # Unsqueeze user_embedding to make it (1, dim) for broadcasting with item_embeddings (n_items, dim)\n    scores = minkowski_inner(user_embedding.unsqueeze(0), item_embeddings)\n\n    # Create a mask for interacted items\n    interacted_mask = torch.zeros(item_embeddings.shape[0], dtype=torch.bool, device=device)\n    interacted_mask[user_history] = True\n\n    # Set scores of interacted items to a very small negative number to exclude them\n    scores[interacted_mask] = -1e9\n\n    # Get the top-K recommended item IDs\n    # `topk` returns both values and indices; we only need indices\n    _, top_k_indices = torch.topk(scores, k)\n\n    return top_k_indices\n\ndef calculate_hit_rate(recommended_items, ground_truth_item):\n    \"\"\"\n    Calculates if the ground-truth item is present in the recommended items.\n\n    Args:\n        recommended_items (list or array-like): A list or array of recommended item IDs.\n        ground_truth_item (int): The single ground-truth item ID.\n\n    Returns:\n        int: 1 if the ground-truth item is in the recommendations, 0 otherwise.\n    \"\"\"\n    if ground_truth_item is None:\n        return 0\n    return 1 if ground_truth_item in recommended_items else 0\n\nimport math\n\ndef calculate_ndcg(recommended_items, ground_truth_item):\n    \"\"\"\n    Calculates the Normalized Discounted Cumulative Gain (NDCG) for a single user.\n\n    Args:\n        recommended_items (list or array-like): A list or array of recommended item IDs.\n        ground_truth_item (int): The single ground-truth item ID.\n\n    Returns:\n        float: The NDCG score.\n    \"\"\"\n    if ground_truth_item is None:\n        return 0.0\n\n    # Calculate IDCG (Ideal Discounted Cumulative Gain)\n    # For a single relevant item, if present, ideal gain is 1 at position 0, so IDCG = 1/log2(0+2) = 1/1 = 1\n    idcg = 1.0\n\n    # Calculate DCG (Discounted Cumulative Gain)\n    dcg = 0.0\n    if ground_truth_item in recommended_items:\n        rank = recommended_items.index(ground_truth_item) # 0-indexed rank\n        dcg = 1.0 / math.log2(rank + 1 + 1) # +1 for 1-based log, +1 for 0-indexed rank\n\n    # Calculate NDCG\n    return dcg / idcg\n\ndef calculate_coverage(all_recommended_items, total_n_items):\n    \"\"\"\n    Calculates the coverage metric.\n\n    Args:\n        all_recommended_items (list or set): A collection of all unique recommended item IDs.\n        total_n_items (int): The total number of available items in the catalog.\n\n    Returns:\n        float: The coverage score.\n    \"\"\"\n    unique_recommended_items = set(all_recommended_items)\n    num_unique_recommended = len(unique_recommended_items)\n\n    if total_n_items == 0:\n        return 0.0\n\n    coverage = num_unique_recommended / total_n_items\n    return coverage\n\ndef evaluate_model(item_embeddings, users_items_test_history, users_items_holdout_targets, valid_users_eval, k):\n    hit_rates = []\n    ndcg_scores = []\n    all_recommended_items_set = set()\n\n    for user_id in tqdm(valid_users_eval, desc=f\"Evaluating @{k}\"):\n        user_history = users_items_test_history[user_id]\n        holdout_item = users_items_holdout_targets[user_id]\n\n        if holdout_item is None:\n            # If there's no holdout item, we can't evaluate for this user, skip\n            continue\n\n        user_history_tensor = torch.tensor(user_history, dtype=torch.long, device=device)\n        user_embedding = compute_user_embedding(user_history_tensor, item_embeddings)\n\n        # Get recommendations (tensor of item IDs)\n        recommendations_tensor = get_recommendations(user_embedding, item_embeddings, user_history_tensor, k)\n        # Convert to a Python list for calculate_hit_rate and calculate_ndcg\n        recommendations_list = recommendations_tensor.cpu().numpy().flatten().tolist()\n\n        # Calculate Hit Rate\n        hr_score = calculate_hit_rate(recommendations_list, holdout_item)\n        hit_rates.append(hr_score)\n\n        # Calculate NDCG\n        ndcg_score = calculate_ndcg(recommendations_list, holdout_item)\n        ndcg_scores.append(ndcg_score)\n\n        # Collect all recommended items for coverage\n        all_recommended_items_set.update(recommendations_list)\n\n    # Calculate average metrics\n    avg_hit_rate = sum(hit_rates) / len(hit_rates) if hit_rates else 0.0\n    avg_ndcg = sum(ndcg_scores) / len(ndcg_scores) if ndcg_scores else 0.0\n\n    # Calculate Coverage\n    total_n_items = item_cnt # item_cnt is available in the kernel state\n    coverage = calculate_coverage(all_recommended_items_set, total_n_items)\n\n    return avg_hit_rate, avg_ndcg, coverage\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-25T02:50:51.294287Z","iopub.execute_input":"2025-12-25T02:50:51.294540Z","iopub.status.idle":"2025-12-25T02:50:57.705687Z","shell.execute_reply.started":"2025-12-25T02:50:51.294515Z","shell.execute_reply":"2025-12-25T02:50:57.705109Z"}},"outputs":[],"execution_count":52},{"cell_type":"code","source":"avg_hit_rate, avg_ndcg, coverage = evaluate_model(item_embeddings, users_items_test_history, users_items_holdout_targets, valid_users_eval, 20)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-25T02:50:57.707856Z","iopub.execute_input":"2025-12-25T02:50:57.708039Z","iopub.status.idle":"2025-12-25T02:50:58.779620Z","shell.execute_reply.started":"2025-12-25T02:50:57.708025Z","shell.execute_reply":"2025-12-25T02:50:58.778908Z"}},"outputs":[{"name":"stderr","text":"Evaluating @20: 100%|██████████| 813/813 [00:01<00:00, 786.18it/s]\n","output_type":"stream"}],"execution_count":53},{"cell_type":"code","source":"print(f\"HyperbolicItemGNNRecommender ndcg={avg_ndcg:.6g}  coverage={coverage:.6g}  hitrate={avg_hit_rate:.6g}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-25T02:54:16.410968Z","iopub.execute_input":"2025-12-25T02:54:16.411541Z","iopub.status.idle":"2025-12-25T02:54:16.415074Z","shell.execute_reply.started":"2025-12-25T02:54:16.411516Z","shell.execute_reply":"2025-12-25T02:54:16.414352Z"}},"outputs":[{"name":"stdout","text":"HyperbolicItemGNNRecommender ndcg=0.00589946  coverage=0.0404749  hitrate=0.0123001\n","output_type":"stream"}],"execution_count":59}]}